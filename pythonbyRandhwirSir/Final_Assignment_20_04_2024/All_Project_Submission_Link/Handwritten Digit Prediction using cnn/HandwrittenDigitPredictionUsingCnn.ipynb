{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr  #to construct web components\n",
    "import tensorflow as tf#perform operation on neural networks\n",
    "import numpy as np #numpy is numeric python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_func():\n",
    "    (x_train,y_train),(x_test,y_test) = tf.keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train[0] # all are pixel format\n",
    "# picels of a single image\n",
    "# o stands for black color and 1 stands for white color\n",
    "#max range is 0 to 253"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#if data has high std , the data doesn't train very well...\n",
    "#some are 0 and some are 253 so high std so not good training of data\n",
    "#to deal with this thing we use normalisation.\n",
    "x_train = x_train/255.0\n",
    "x_test = x_test/255.0 #doing normalisation to make std close enough.\n",
    "#so it won't be able to predict the good accuracy from the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train[0]\n",
    "#so we can see that all values does not have a high standard deviation\n",
    "#so training of data will be good and efficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.reshape(-1,28,28,1)\n",
    "x_test = x_test.reshape(-1,28,28,1)\n",
    "#reshaping to 28 rows and 28 columns\n",
    "#-1 figures out kitni image hai in the set and 1 acts as another \n",
    "#dimension to image\n",
    "#converting 2d to 3d putting 1 at the last"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train=tf.keras.utils.to_categorical(y_train,num_classes=10)\n",
    "y_test=tf.keras.utils.to_categorical(y_test,num_classes=10)\n",
    "#we divided the images into classes from the info inside y\n",
    "#from 0 to 9 range so 10 uunique values......."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1st linme - squential creates a container in which we built the nrural network\n",
    "\n",
    "creating layers in covo 2d ke format me , 1st hidden layers, 32 filter layers 3 by 3 ke...... input shape 28*28 ka hai , image ka shape mtlb\n",
    "next input shape use karke input de diya hai apan ne upar wali line me\n",
    "we perform maxpooling to convert to 2*2\n",
    "then we flatten to put input to the input layer in 128 ke format\n",
    "then we passes 10 classes or 10 output to see kitne unique items ki kitni probability hai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Conv2D(32,(3,3),activation = 'relu',input_shape=(28,28,1)))\n",
    "#input_shape = (28,28,1)\n",
    "model.add(tf.keras.layers.MaxPooling2D(2,2))\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "model.add(tf.keras.layers.Dense(128,activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(10,activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',loss='categorical_crossentropy',\n",
    "            metrics=['accuracy']) #compile the model , kitne error aarha hai , input ouput ke beech ka diff\n",
    "#optimizer help karkta hai adam nam ka to reduce the error. for the high\n",
    "#efficiency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()  #total summary of the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#running the algo how much times\n",
    "#validation split = kitne percent data prr perform karna hgaui\n",
    "#batch size 128 data from the whole batch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x_train,y_train,epochs=10,batch_size=128,validation_split=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = model.evaluate(x_test,y_test)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sketch_recognition(img):\n",
    "    x=model.predict(img.reshape(1,28,28)).argmax(axis=1)\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interface = gr.Interface(fn=sketch_recognition,inputs=\"sketchpad\",\n",
    "                         outputs='text')\n",
    "interface.launch(debug=True)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
